{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d3a358a-65f1-43b7-a5cf-e3516582cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging , os\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "from ocpa.objects.log.importer.csv import factory as csv_import_factory\n",
    "from ocpa.algo.predictive_monitoring import factory as predictive_monitoring\n",
    "\n",
    "from preprocessing import *\n",
    "from utils import *\n",
    "from model import CustomPipeline, train_loop, evaluate\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import optim\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c43595c-572e-41d0-9afb-763e04f6eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to transform the ocel into csv format (supported extensions \"xml\", \"jsonocel\", \"sqlite\")\n",
    "# ocel_to_csv(file_path, new_file_path, file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5844fd3-f51c-4331-9e0d-1325a9c65b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target functions\n",
    "reg_funcs = [remaining_time]\n",
    "class_funcs = [num_events, num_objects, num_unique_acts]\n",
    "# Create result dataframe\n",
    "task_names = [f.__name__ for f in reg_funcs] + [f.__name__ for f in class_funcs]\n",
    "# Set the value of no_feats to:\n",
    "# - True to use the graph structure only as input\n",
    "# - False to use event-level features detailed in main_function\n",
    "no_feat = False\n",
    "# List of subgraph sizes to use\n",
    "ks = range(3, 15)\n",
    "# Graph embedding module to use\n",
    "embedding_name_list = [\"GAT\", \"GCN\", \"GraphTransformer\", \"Graph2Vec\", \"FGSD\"]\n",
    "embedding_name = \"GAT\"\n",
    "# Predictors to use\n",
    "regressor = LinearRegression\n",
    "classifier = LogisticRegression\n",
    "# Model hyperparameters\n",
    "embedding_size = 8\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "mlp_hidden_dim = 16\n",
    "mlp_num_layers = 2\n",
    "# OCEL name and object types to use\n",
    "filename = \"recruiting-ocel1\"\n",
    "object_types = ['applicants', 'applications', 'offers']\n",
    "parameters = {\"obj_names\": object_types,\n",
    "              \"val_names\": [],\n",
    "              \"act_name\": \"activity\",\n",
    "              \"time_name\": \"timestamp\",\n",
    "              \"sep\": \",\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c73fbc-f344-4e51-a20d-edd6ae2f6b4c",
   "metadata": {},
   "source": [
    "#### OCEL file import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0373826a-67f3-47b7-bb5a-79a16565b950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing OCEL recruiting-ocel1\n",
      "OCEL Imported successfully\n"
     ]
    }
   ],
   "source": [
    "print(f\"Importing OCEL {filename}\")\n",
    "file_path = os.path.join('.', 'ocel', 'csv', filename)\n",
    "ocel = csv_import_factory.apply(file_path=file_path + '.csv', parameters=parameters)\n",
    "print(\"OCEL Imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c99659-8ad2-4c2e-9bb5-d440dabe65a6",
   "metadata": {},
   "source": [
    "#### Feature and target definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "13c2225a-9d4e-48e9-929c-f89271e92d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = list(set(ocel.log.log[\"event_activity\"].tolist()))\n",
    "\n",
    "# Event level targets\n",
    "event_target_set = [(predictive_monitoring.EVENT_REMAINING_TIME, ())]\n",
    "\n",
    "# Execution level targets (Outcome related)\n",
    "execution_target_set = [(predictive_monitoring.EXECUTION_NUM_OBJECT, ()),\n",
    "                        (predictive_monitoring.EXECUTION_NUM_OF_EVENTS, ()),\n",
    "                        (predictive_monitoring.EXECUTION_UNIQUE_ACTIVITIES, ())]\n",
    "if no_feat:\n",
    "    execution_feature_set = []\n",
    "    event_feature_set = []\n",
    "else:\n",
    "    # Event level features\n",
    "    event_feature_set = [(predictive_monitoring.EVENT_ELAPSED_TIME, ()),\n",
    "                         (predictive_monitoring.EVENT_NUM_OF_OBJECTS, ())] + \\\n",
    "                        [(predictive_monitoring.EVENT_ACTIVITY, (act,)) for act in activities]\n",
    "    # [(predictive_monitoring.EVENT_PRECEDING_ACTIVITIES, (act,)) for act in activities] + \\\n",
    "    execution_feature_set = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a4146-b041-44b7-b6ae-18678841e869",
   "metadata": {},
   "source": [
    "#### Process Execution Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12498413-eab4-4e16-8c31-9323d3550269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying feature extraction to process executions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 661/661 [00:00<00:00, 330327.05it/s]\n"
     ]
    }
   ],
   "source": [
    "PE_nx = get_process_executions_nx(ocel, event_feature_set, event_target_set, execution_feature_set,execution_target_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa18d53-c50d-45f6-b12c-d8433237a9c8",
   "metadata": {},
   "source": [
    "#### Preprocessing process executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37182bf7-a1e9-4715-9ec7-9b01501df8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose k\n",
    "k = ks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36c5b995-b1df-480b-b773-1af1b6d507c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subgraphs of length 3\n",
      "Using subgraphs of length 4\n",
      "Using subgraphs of length 5\n",
      "Using subgraphs of length 6\n",
      "Using subgraphs of length 7\n",
      "Using subgraphs of length 8\n",
      "Using subgraphs of length 9\n",
      "Using subgraphs of length 10\n",
      "Using subgraphs of length 11\n",
      "Using subgraphs of length 12\n",
      "Using subgraphs of length 13\n",
      "Using subgraphs of length 14\n"
     ]
    }
   ],
   "source": [
    "# Script to build the generate the input data and \n",
    "print(f\"Using subgraphs of length {k}\")\n",
    "subgraph_list = get_subgraphs_labeled(PE_nx, k=k, subg_funcs=reg_funcs,\n",
    "                                      g_funcs=class_funcs)\n",
    "pred_types = get_pred_types(subgraph_list, reg_funcs, class_funcs, task_names)\n",
    "\n",
    "# Create result dataframes and corresponding dirs\n",
    "create_res_dfs(filename, task_names, k)\n",
    "# Scale numerical targets and encode categorical targets\n",
    "scaler = scale_encode_targets(subgraph_list, pred_types)\n",
    "\n",
    "# Prepare input data and scale temporal feature\n",
    "idx_feats_to_scale = [0]\n",
    "input_dataset = generate_matrix_dataset(subgraph_list, idx_feats_to_scale, k, no_feat)\n",
    "num_features = input_dataset[0].x.shape[1]\n",
    "\n",
    "# train val test split\n",
    "temp_data, test_data = train_test_split(input_dataset, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(temp_data, test_size=0.2, random_state=42)\n",
    "# data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc0129-31d4-492a-b3ed-834f87a6df1f",
   "metadata": {},
   "source": [
    "#### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84760da2-f929-46d0-8c6f-1c84b724fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Embedding component\n",
    "embedding_layer = init_embedding_component(embedding_name, num_features, embedding_size, train_data)\n",
    "# Build Predictor component\n",
    "nn_preds, ml_preds = init_pred_component(regressor, classifier, embedding_size, mlp_hidden_dim, mlp_num_layers, pred_types)\n",
    "\n",
    "# Init pipeline\n",
    "model = CustomPipeline(embedding_layer, nn_preds, ml_preds)\n",
    "# Init optimizer\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ac55ef-15c7-4133-9268-76800cc94e8d",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "657c06ce-a9e9-44ce-91ca-d024dfc83941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "train_loop(model, optimizer, train_loader, val_loader, pred_types, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ceded9-42e0-4443-97dc-ca89ebdcc988",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee7798e9-8c7d-42cd-ab2b-3ad96ef256b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage creation\n",
    "result_dfs = []\n",
    "result_dir_paths = []\n",
    "for task_name in task_names:\n",
    "    result_df = pd.DataFrame(columns=['prediction_layer', 'score'])\n",
    "    result_dfs.append(result_df)\n",
    "    result_dir_path = os.path.join('.', 'results', filename, task_name, str(k))\n",
    "    result_dir_paths.append(result_dir_path)\n",
    "    os.makedirs(result_dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f149e35-56ea-48a9-9ba0-13bc06456fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining_time\n",
      "          prediction_layer      score\n",
      "0  LinearRegression models  17.763668\n",
      "num_events\n",
      "            prediction_layer     score\n",
      "0  LogisticRegression models  0.604003\n",
      "num_objects\n",
      "            prediction_layer     score\n",
      "0  LogisticRegression models  0.369887\n",
      "num_unique_acts\n",
      "            prediction_layer     score\n",
      "0  LogisticRegression models  0.597911\n"
     ]
    }
   ],
   "source": [
    "# Tests on linear ml models\n",
    "_, test_ml_scores = evaluate(model, test_loader, pred_types, train_loader)\n",
    "# Store test scores for nn and ml\n",
    "for i, result_df in enumerate(result_dfs):\n",
    "    if pred_types[i] is None:\n",
    "        b = scaler.inverse_transform(test_ml_scores[i].reshape(-1, 1))[0][0]\n",
    "        res_row = [f\"{regressor.__name__} models\", b / 86400]\n",
    "        result_df.loc[len(result_df)] = res_row\n",
    "    else:\n",
    "        res_row = [f\"{classifier.__name__} models\", test_ml_scores[i]]\n",
    "        result_df.loc[len(result_df)] = res_row\n",
    "for i, result_df in enumerate(result_dfs):\n",
    "    print(task_names[i])\n",
    "    print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4cae7e-9941-4cee-a3fc-1db7afbccfed",
   "metadata": {},
   "source": [
    "#### Evaluate on other predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bec382b0-22c0-4e57-9141-1dd1e2791920",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_regressor = RandomForestRegressor\n",
    "new_classifier = RandomForestClassifier\n",
    "new_predictors = set_new_ml_preds(new_regressor, new_classifier, pred_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "656dcb52-d8d2-4c57-9972-f3803fc198fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining_time\n",
      "               prediction_layer      score\n",
      "0       LinearRegression models  17.763668\n",
      "1  RandomForestRegressor models  18.433195\n",
      "num_events\n",
      "               prediction_layer     score\n",
      "0     LogisticRegression models  0.604003\n",
      "1  RandomForestRegressor models  0.561358\n",
      "num_objects\n",
      "               prediction_layer     score\n",
      "0     LogisticRegression models  0.369887\n",
      "1  RandomForestRegressor models  0.332463\n",
      "num_unique_acts\n",
      "               prediction_layer     score\n",
      "0     LogisticRegression models  0.597911\n",
      "1  RandomForestRegressor models  0.542211\n"
     ]
    }
   ],
   "source": [
    " _, test_ml_scores = evaluate(model, test_loader, pred_types, train_loader, new_ml_predictors=new_predictors)\n",
    "for i, result_df in enumerate(result_dfs):\n",
    "    if pred_types[i] is None:\n",
    "        b = scaler.inverse_transform(test_ml_scores[i].reshape(-1, 1))[0][0]\n",
    "        res_row = [f\"{new_regressor.__name__} models\", b / 86400]\n",
    "        result_df.loc[len(result_df)] = res_row\n",
    "    else:\n",
    "        res_row = [f\"{new_regressor.__name__} models\", test_ml_scores[i]]\n",
    "        result_df.loc[len(result_df)] = res_row\n",
    "for i, result_df in enumerate(result_dfs):\n",
    "    print(task_names[i])\n",
    "    print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd04c7c-500a-4e0e-9207-ec158d3b69c0",
   "metadata": {},
   "source": [
    "### Scores storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e54e238-f6a8-4456-9233-d30ba8f24044",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, result_df in enumerate(result_dfs):\n",
    "    result_file_path = os.path.join(result_dir_paths[i], f\"{embedding_name}_{embedding_size}_{no_feat}.csv\")\n",
    "    result_df.to_csv(result_file_path, mode='a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
